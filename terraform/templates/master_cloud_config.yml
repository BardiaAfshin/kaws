#cloud-config

coreos:
  etcd2:
    proxy: on
    initial_cluster: etcd_01=http://10.0.1.4:2380,etcd_02=http://10.0.1.5:2380,etcd_03=http://10.0.1.6:2380
    listen-client-urls: http://127.0.0.1:2379
  flannel:
    etcd_endpoints: http://127.0.0.1:2379
    interface: $private_ipv4
  fleet:
    etcd-servers: http://127.0.0.1:2379
    metadata: etcd=proxy,kubernetes=master
    public-ip: $private_ipv4
  units:
    - name: docker.service
      command: start
      drop-ins:
        - name: 40-flannel.conf
          content: |
            [Unit]
            Requires=flanneld.service
            After=flanneld.service
        - name: 50-opts.conf
          content: |
            [Service]
            Environment=DOCKER_OPTS='--log-driver=journald'
    - name: etcd2.service
      command: start
    - name: flanneld.service
      command: start
      drop-ins:
        - name: 50-network-config.conf
          content: |
            [Unit]
            Requires=etcd2.service
            [Service]
            ExecStartPre=-/usr/bin/etcdctl mk /coreos.com/network/config "{\"Network\":\"10.2.0.0/16\"}"
    - name: fleet.service
      command: start
    - name: kaws-agent.service
      command: start
      content: |
        [Unit]
        Description=kaws agent
        Requires=etcd2.service
        After=etcd2.service
        [Service]
        TimeoutStartSec=0
        ExecStartPre=/bin/bash -c 'until curl -sf "http://127.0.0.1:2379/v2/keys/kaws"; do sleep 5; done'
        ExecStart=/usr/bin/rkt --insecure-options image run \
          --volume etc-kubernetes,kind=host,source=/etc/kubernetes \
          --volume etc-resolve-conf,kind=host,source=/etc/resolv.conf \
          --mount volume=etc-kubernetes,target=/etc/kubernetes \
          --mount volume=etc-resolve-conf,target=/etc/resolv.conf \
          --stage1-from-dir stage1-fly.aci \
          docker://inquicker/kaws-agent \
          -- \
          run \
          --region ${region} \
          --role master
        KillMode=mixed
        Restart=always
        [Install]
        WantedBy=multi-user.target
    - name: kubelet.service
      command: start
      content: |
        [Unit]
        Description=Kubernetes Kubelet
        Requires=kaws-agent.service
        After=kaws-agent.service
        [Service]
        ExecStartPre=/usr/bin/mkdir -p /var/lib/kubelet /opt/bin
        ExecStartPre=/usr/bin/curl -L -o /opt/bin/kubelet -z /opt/bin/kubelet https://storage.googleapis.com/kubernetes-release/release/v${version}/bin/linux/amd64/kubelet
        ExecStartPre=/usr/bin/chmod +x /opt/bin/kubelet
        ExecStart=/opt/bin/kubelet \
          --allow-privileged=true \
          --api-servers=http://127.0.0.1:8080 \
          --cloud-provider=aws \
          --cluster-dns=10.3.0.10 \
          --cluster-domain=cluster.local \
          --config=/etc/kubernetes/manifests \
          --hostname-override=$private_ipv4 \
          --logtostderr=true \
          --register-schedulable=false \
          --v=2
        Restart=always
        RestartSec=10
        [Install]
        WantedBy=multi-user.target
    - name: restart-kubelet@.path
      content: |
        [Unit]
        Description=Restart kubelet if %f changes
        [Path]
        PathChanged=%f
        Unit=restart-kube.service
    - name: restart-kubelet@etc-kubernetes-ssl-ca.pem.path
      enable: true
      command: start
    - name: restart-kubelet@etc-kubernetes-ssl-master.pem.path
      enable: true
      command: start
    - name: restart-kubelet@etc-kubernetes-ssl-master\x2dkey.pem.path
      enable: true
      command: start
    - name: restart-kubelet.service
      content: |
        [Unit]
        Description=Restart kubelet
        [Service]
        Type=oneshot
        ExecStart=/usr/bin/systemctl restart kubelet
    - name: start-kube-addons.service
      command: start
      content: |
        [Unit]
        Description=Kubernetes addons
        [Service]
        ExecStartPre=/usr/bin/curl http://127.0.0.1:8080/version
        ExecStart=/opt/bin/start-kube-addons
        StartLimitInterval=0
        Restart=on-failure
write_files:
  - path: /etc/kubernetes/manifests/kube-apiserver.yml
    permissions: "0644"
    owner: root
    content: |
      apiVersion: v1
      kind: Pod
      metadata:
        name: kube-apiserver
        namespace: kube-system
      spec:
        hostNetwork: true
        containers:
        - name: kube-apiserver
          image: gcr.io/google_containers/hyperkube:v${version}
          command:
          - /hyperkube
          - apiserver
          - --admission-control=NamespaceLifecycle,NamespaceExists,LimitRanger,SecurityContextDeny,ServiceAccount,ResourceQuota
          - --advertise-address=$private_ipv4
          - --allow-privileged=true
          - --bind-address=0.0.0.0
          - --client-ca-file=/etc/kubernetes/ssl/ca.pem
          - --cloud-provider=aws
          - --etcd-servers=http://127.0.0.1:2379
          - --external-hostname=https://kubernetes.${domain}
          - --insecure-bind-address=0.0.0.0
          - --secure-port=443
          - --service-account-key-file=/etc/kubernetes/ssl/master-key.pem
          - --service-cluster-ip-range=10.3.0.1/24
          - --tls-cert-file=/etc/kubernetes/ssl/master.pem
          - --tls-private-key-file=/etc/kubernetes/ssl/master-key.pem
          ports:
          - containerPort: 443
            hostPort: 443
            name: https
          - containerPort: 8080
            hostPort: 8080
            name: local
          volumeMounts:
          - mountPath: /etc/kubernetes/ssl
            name: ssl-certs-kubernetes
            readOnly: true
          - mountPath: /etc/ssl/certs
            name: ssl-certs-host
            readOnly: true
        volumes:
        - hostPath:
            path: /etc/kubernetes/ssl
          name: ssl-certs-kubernetes
        - hostPath:
            path: /usr/share/ca-certificates
          name: ssl-certs-host
  - path: /etc/kubernetes/manifests/kube-proxy.yml
    permissions: "0644"
    owner: root
    content: |
      apiVersion: v1
      kind: Pod
      metadata:
        name: kube-proxy
        namespace: kube-system
      spec:
        hostNetwork: true
        containers:
        - name: kube-proxy
          image: gcr.io/google_containers/hyperkube:v${version}
          command:
          - /hyperkube
          - proxy
          - --master=http://127.0.0.1:8080
          - --proxy-mode=iptables
          securityContext:
            privileged: true
          volumeMounts:
          - mountPath: /etc/ssl/certs
            name: ssl-certs-host
            readOnly: true
        volumes:
        - hostPath:
            path: /usr/share/ca-certificates
          name: ssl-certs-host
  - path: /etc/kubernetes/ssl/ca.pem
    permissions: "0644"
    owner: "root"
    content: ""
  - path: /etc/kubernetes/ssl/master.pem
    permissions: "0644"
    owner: "root"
    content: ""
  - path: /etc/kubernetes/ssl/master-key.pem
    permissions: "0600"
    owner: "root"
    content: ""
  - path: /etc/kubernetes/manifests/kube-controller-manager.yml
    permissions: "0644"
    owner: root
    content: |
      apiVersion: v1
      kind: Pod
      metadata:
        name: kube-controller-manager
        namespace: kube-system
      spec:
        containers:
        - name: kube-controller-manager
          image: gcr.io/google_containers/hyperkube:v${version}
          command:
          - /hyperkube
          - controller-manager
          - --cloud-provider=aws
          - --leader-elect=true
          - --master=http://127.0.0.1:8080
          - --root-ca-file=/etc/kubernetes/ssl/ca.pem
          - --service-account-private-key-file=/etc/kubernetes/ssl/master-key.pem
          livenessProbe:
            httpGet:
              host: 127.0.0.1
              path: /healthz
              port: 10252
            initialDelaySeconds: 15
            timeoutSeconds: 1
          volumeMounts:
          - mountPath: /etc/kubernetes/ssl
            name: ssl-certs-kubernetes
            readOnly: true
          - mountPath: /etc/ssl/certs
            name: ssl-certs-host
            readOnly: true
        hostNetwork: true
        volumes:
        - hostPath:
            path: /etc/kubernetes/ssl
          name: ssl-certs-kubernetes
        - hostPath:
            path: /usr/share/ca-certificates
          name: ssl-certs-host
  - path: /etc/kubernetes/manifests/kube-scheduler.yml
    permissions: "0644"
    owner: root
    content: |
      apiVersion: v1
      kind: Pod
      metadata:
        name: kube-scheduler
        namespace: kube-system
      spec:
        hostNetwork: true
        containers:
        - name: kube-scheduler
          image: gcr.io/google_containers/hyperkube:v${version}
          command:
          - /hyperkube
          - scheduler
          - --master=http://127.0.0.1:8080
          - --leader-elect=true
          livenessProbe:
            httpGet:
              host: 127.0.0.1
              path: /healthz
              port: 10251
            initialDelaySeconds: 15
            timeoutSeconds: 1
  - path: /opt/bin/start-kube-addons
    permissions: "0700"
    owner: root
    content: |
      #!/bin/bash -e
      curl -H "Content-Type: application/json" -X POST -d @/srv/kubernetes/kube-system.json "http://127.0.0.1:8080/api/v1/namespaces"
      curl -H "Content-Type: application/json" -X POST -d @/srv/kubernetes/kube-dns-svc.json "http://127.0.0.1:8080/api/v1/namespaces/kube-system/services"
      curl -H "Content-Type: application/json" -X POST -d @/srv/kubernetes/kube-dns-rc.json "http://127.0.0.1:8080/api/v1/namespaces/kube-system/replicationcontrollers"
  - path: /srv/kubernetes/kube-dns-rc.json
    permissions: "0644"
    owner: root
    content: |
      {
        "apiVersion": "v1",
        "kind": "ReplicationController",
        "metadata": {
          "labels": {
            "k8s-app": "kube-dns",
            "kubernetes.io/cluster-service": "true",
            "version": "v11"
          },
          "name": "kube-dns-v11",
          "namespace": "kube-system"
        },
        "spec": {
          "replicas": 1,
          "selector": {
            "k8s-app": "kube-dns",
            "version": "v11"
          },
          "template": {
            "metadata": {
              "labels": {
                "k8s-app": "kube-dns",
                "kubernetes.io/cluster-service": "true",
                "version": "v11"
              }
            },
            "spec": {
              "containers": [
                {
                  "command": [
                    "/usr/local/bin/etcd",
                    "-data-dir",
                    "/var/etcd/data",
                    "-listen-client-urls",
                    "http://127.0.0.1:2379,http://127.0.0.1:4001",
                    "-advertise-client-urls",
                    "http://127.0.0.1:2379,http://127.0.0.1:4001",
                    "-initial-cluster-token",
                    "skydns-etcd"
                  ],
                  "image": "gcr.io/google_containers/etcd-amd64:2.2.1",
                  "name": "etcd",
                  "resources": {
                    "limits": {
                      "cpu": "100m",
                      "memory": "500Mi"
                    },
                    "requests": {
                      "cpu": "100m",
                      "memory": "50Mi"
                    }
                  },
                  "volumeMounts": [
                    {
                      "mountPath": "/var/etcd/data",
                      "name": "etcd-storage"
                    }
                  ]
                },
                {
                  "args": [
                    "--domain=cluster.local"
                  ],
                  "image": "gcr.io/google_containers/kube2sky:1.14",
                  "livenessProbe": {
                    "failureThreshold": 5,
                    "httpGet": {
                      "path": "/healthz",
                      "port": 8080,
                      "scheme": "HTTP"
                    },
                    "initialDelaySeconds": 60,
                    "successThreshold": 1,
                    "timeoutSeconds": 5
                  },
                  "name": "kube2sky",
                  "readinessProbe": {
                    "httpGet": {
                      "path": "/readiness",
                      "port": 8081,
                      "scheme": "HTTP"
                    },
                    "initialDelaySeconds": 30,
                    "timeoutSeconds": 5
                  },
                  "resources": {
                    "limits": {
                      "cpu": "100m",
                      "memory": "200Mi"
                    },
                    "requests": {
                      "cpu": "100m",
                      "memory": "50Mi"
                    }
                  }
                },
                {
                  "args": [
                    "-machines=http://127.0.0.1:4001",
                    "-addr=0.0.0.0:53",
                    "-ns-rotate=false",
                    "-domain=cluster.local."
                  ],
                  "image": "gcr.io/google_containers/skydns:2015-10-13-8c72f8c",
                  "name": "skydns",
                  "ports": [
                    {
                      "containerPort": 53,
                      "name": "dns",
                      "protocol": "UDP"
                    },
                    {
                      "containerPort": 53,
                      "name": "dns-tcp",
                      "protocol": "TCP"
                    }
                  ],
                  "resources": {
                    "limits": {
                      "cpu": "100m",
                      "memory": "200Mi"
                    },
                    "requests": {
                      "cpu": "100m",
                      "memory": "50Mi"
                    }
                  }
                },
                {
                  "args": [
                    "-cmd=nslookup kubernetes.default.svc.cluster.local 127.0.0.1 >/dev/null",
                    "-port=8080",
                    "-quiet"
                  ],
                  "image": "gcr.io/google_containers/exechealthz:1.0",
                  "name": "healthz",
                  "ports": [
                    {
                      "containerPort": 8080,
                      "protocol": "TCP"
                    }
                  ],
                  "resources": {
                    "limits": {
                      "cpu": "10m",
                      "memory": "20Mi"
                    },
                    "requests": {
                      "cpu": "10m",
                      "memory": "20Mi"
                    }
                  }
                }
              ],
              "dnsPolicy": "Default",
              "volumes": [
                {
                  "emptyDir": {},
                  "name": "etcd-storage"
                }
              ]
            }
          }
        }
      }
  - path: /srv/kubernetes/kube-dns-svc.json
    permissions: "0644"
    owner: root
    content: |
      {
        "apiVersion": "v1",
        "kind": "Service",
        "metadata": {
          "name": "kube-dns",
          "namespace": "kube-system",
          "labels": {
            "k8s-app": "kube-dns",
            "kubernetes.io/name": "KubeDNS",
            "kubernetes.io/cluster-service": "true"
          }
        },
        "spec": {
          "clusterIP": "10.3.0.10",
          "ports": [
            {
              "protocol": "UDP",
              "name": "dns",
              "port": 53
            },
            {
              "protocol": "TCP",
              "name": "dns-tcp",
              "port": 53
            }
          ],
          "selector": {
            "k8s-app": "kube-dns"
          }
        }
      }
  - path: /srv/kubernetes/kube-system.json
    permissions: "0644"
    owner: root
    content: |
      {
        "apiVersion": "v1",
        "kind": "Namespace",
        "metadata": {
          "name": "kube-system"
        }
      }
